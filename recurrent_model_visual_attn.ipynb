{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Defining all the global variables in this cell\n",
    "'''\n",
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "IMG_DEPTH = 1\n",
    "\n",
    "G_WIN_SIZE= 8\n",
    "G_DIM = G_WIN_SIZE*G_WIN_SIZE*IMG_DEPTH\n",
    "\n",
    "LOC_DIM = 2 # the number of dimensions for the locations are just x and y so 2\n",
    "GLIMPSE_FC1 = 128\n",
    "GLIMPSE_FC2 = 256\n",
    "\n",
    "LSTM_HIDDEN = 256\n",
    "\n",
    "NUM_GLIMPSES = 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, inputs, b_size):\n",
    "        self.inputs= inputs\n",
    "        self.batch_size = b_size\n",
    "        \n",
    "    def __call__(self, inputs, b_size)\n",
    "        # Normal instead of uniform \n",
    "        initial_locs = tf.random_uniform([batch_size, LOC_DIM], minval=-1, maxval=1)\n",
    "        input_lstm = self.glimpse_network(self.inputs, initial_locs)\n",
    "\n",
    "        lstm_cell  = tf.nn.rnn_cell.LSTMCell(LSTM_HIDDEN, state_is_tuple=True)\n",
    "        init_state = lstm_cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        inputs = np.zeros((NUM_GLIMPSES, batch_size, GLIMPSE_FC2))\n",
    "        inputs[0] = input_lstm\n",
    "\n",
    "        outputs, state = tf.contrib.legacy_seq2seq.rnn_decoder(inputs, init_state, \n",
    "                                                               lstm_cell, loop_function=next_location)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "    def next_location(self, prev_inputs, i):\n",
    "        # Change this function to have all the variables defined here so that stop gradients can be applied.\n",
    "        locs = self.fc_layer(prev_inputs, GLIMPSE_FC2, LOC_DIM, 'next_loc', None)\n",
    "        locs = tf.clip_by_value(next_loc, -1., 1.)\n",
    "        locs = tf.stop_gradient(next_loc)\n",
    "\n",
    "        next_inputs = self.glimpse_network(self.inputs, locs)\n",
    "\n",
    "        return next_inputs\n",
    "\n",
    "\n",
    "    def glimpse_network(self, input_img, locations):\n",
    "\n",
    "        loc_out1 = self.fc_layer(locations, LOC_DIM, GLIMPSE_FC1, 'lc1', tf.nn.relu)\n",
    "        loc_out2 = self.fc_layer(loc_out1, GLIMPSE_FC1, GLIMPSE_FC2, 'lc2', tf.nn.relu)\n",
    "\n",
    "        glimpses = tf.image.extract_glimpse(input_img, [G_WIN_SIZE,G_WIN_SIZE], \n",
    "                                            locations, centered=True, normalized=True)\n",
    "\n",
    "        glimpses = tf.reshape(glimpses, [-1, G_WIN_SIZE*G_WIN_SIZE*IMG_DEPTH])\n",
    "\n",
    "        g_out1 = self.fc_layer(glimpses, G_DIM, GLIMPSE_FC1, 'g1', tf.nn.relu)\n",
    "        g_out2 = self.fc_layer(g_out1, GLIMPSE_FC1, GLIMPSE_FC2, 'g2', tf.nn.relu)\n",
    "\n",
    "        return tf.nn.relu(loc_out2 + g_out2)\n",
    "\n",
    "\n",
    "    def fc_layer(self, image, in_size, out_size, name, activation):\n",
    "        with tf.variable_scope(name):\n",
    "            weights = tf.get_variable(\"weights\", [in_size, out_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            biases = tf.get_variable(\"biases\", [out_size], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            y = tf.add(tf.matmul(image, weights), biases)\n",
    "            tf.summary.histogram('weights_hist', weights)\n",
    "            tf.summary.histogram('biases_hist', biases)\n",
    "\n",
    "            if activation is not None:\n",
    "                y = activation(y)\n",
    "\n",
    "            return y\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train function\n",
    "Processes inputs in mini-batchs \n",
    "Builds the model and trains the parameters for predetermined number of times \n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os \n",
    "from tensorflow.python.framework import ops\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "def train(batch_size, epochs, log, output):\n",
    "    # Read arguments\n",
    "    ops.reset_default_graph()\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    # placeholders for the input and labels\n",
    "    X = tf.placeholder(tf.float32, [None, INPUT_SIZE], name='X')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='labels')\n",
    "\n",
    "    y_hat = model(X, batch_size)\n",
    "\n",
    "    '''\n",
    "    Calculate loss and then define the Optimizer and related hyper-parameters\n",
    "    '''\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.33\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        merged_summary = tf.summary.merge_all()\n",
    "        writer = tf.summary.FileWriter(log, sess.graph)\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "        # training the model for a predetermined number of epochs\n",
    "        for i in range(epochs):\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            acc = sess.run(y_hat, feed_dict={X: batch[0], y: batch[1]})\n",
    "            s = sess.run(merged_summary, feed_dict={X: batch[0], y: batch[1]})\n",
    "            writer.add_summary(s, i)\n",
    "\n",
    "            if (i+1) % 275 == 0:\n",
    "                print('Step {}: {:.2f}'.format(i+1, acc))\n",
    "\n",
    "            if (((i+1) % 275 == 0) and (acc > 0.99)):\n",
    "                # Please change the directory here to save the model in a different location\n",
    "                params = saver.save(sess, '/N/u/ramyarao/dl_hw2/exp_model/{}_{}.ckpt'.format(output, i+1))\n",
    "                print('Model saved: {}'.format(params))\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    return\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train(200, 275*10000, 'logs', 'model')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
